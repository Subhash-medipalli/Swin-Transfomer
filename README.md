# ğŸŒ€ Swin Transformer

This project implements the **Swin Transformer** architecture for image classification, with experiments on both **CIFAR-10** and **CIFAR-100** datasets.

---

### ğŸš€ Key Highlights

- ğŸ”² **Shifted Window Attention**: Efficient local attention mechanism for better scalability  
- ğŸ§  **Hierarchical Feature Extraction**: Patch merging strategy captures multiscale information  
- ğŸ¯ **Relative Positional Embedding**: Adds spatial context to patch tokens  
- ğŸ” **Data Augmentation**: Applied `RandAugment` to boost generalization  
- âš™ï¸ **Training Pipeline**: Integrated **checkpointing** and **AMP** (automatic mixed precision) for speed and stability  
- ğŸ“Š **Comparison**: Benchmarked against Vision Transformer (ViT) and traditional CNNs

---

### ğŸ§ª Results

Our experiments showed that Swin Transformer:
- âœ… Outperforms traditional CNNs on CIFAR-10
- âš–ï¸ Matches or exceeds ViT performance on CIFAR-100
- ğŸ“ˆ Scales well even with small datasets, maintaining accuracy

---

### ğŸ§° Tech Stack

- `PyTorch`
- `RandAugment`
- `AMP (torch.cuda.amp)`
- `Matplotlib`, `Seaborn` for visualization
- `Weights & Biases` or `TensorBoard` (optional for logging)

---

### ğŸ–¼ Sample Result

- `Check PPTX for the results`

